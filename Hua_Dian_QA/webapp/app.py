import gradio as gr
import os
import logging
from langchain_core.messages import HumanMessage, AIMessage
from Hua_Dian_QA.core.llm_manager import LLMManager
from Hua_Dian_QA.data.vector_store import VectorStore
from Hua_Dian_QA.core.config import DOCS_PATH

# Global variables
llm_manager = None
logger = logging.getLogger(__name__)

def list_docs(doc_path):
    """Lists documents in the specified directory."""
    if not os.path.exists(doc_path):
        return []
    return [f for f in os.listdir(doc_path) if os.path.isfile(os.path.join(doc_path, f))]

def delete_files(files_to_delete):
    """Deletes selected files from the docs directory."""
    if not files_to_delete:
        return "æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ã€‚"
    
    for filename in files_to_delete:
        file_path = os.path.join(DOCS_PATH, filename)
        try:
            os.remove(file_path)
            logger.info(f"Deleted file: {file_path}")
        except OSError as e:
            logger.error(f"Error deleting file {file_path}: {e}")
            return f"åˆ é™¤æ–‡ä»¶ {filename} æ—¶å‡ºé”™ã€‚"

    return f"æˆåŠŸåˆ é™¤ {len(files_to_delete)} ä¸ªæ–‡ä»¶ã€‚å»ºè®®é‡å»ºçŸ¥è¯†åº“ã€‚"

def init_rag(force_rebuild=False):
    """
    Initializes the RAG chain. Can be forced to rebuild the vectorstore.
    """
    global llm_manager
    logger.info("Initializing RAG engine...")
    vs = VectorStore()
    if force_rebuild or not os.path.exists(vs.persist_directory) or not os.listdir(vs.persist_directory):
        logger.info("Rebuilding vector store...")
        documents = vs.load_documents()
        vs.vector_store = vs.create_vector_store(documents)
    
    retriever = vs.get_retriever()
    llm_manager = LLMManager(retriever)
    logger.info("RAG engine initialized.")
    return "é—®ç­”å¼•æ“å·²å°±ç»ªã€‚"

def get_answer(question, history):
    """
    Invokes the RAG chain to get an answer for the given question and history.
    """
    if llm_manager is None:
        logger.warning("RAG engine not initialized. Please initialize it first.")
        return "é—®ç­”å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆåˆå§‹åŒ–ã€‚"

    logger.info(f"Received question: {question}")

    # Convert Gradio history to LangChain history
    chat_history = []
    for user_msg, ai_msg in history:
        chat_history.append(HumanMessage(content=user_msg))
        chat_history.append(AIMessage(content=ai_msg))

    logger.info(f"Chat history contains {len(chat_history)} messages.")

    response = llm_manager.answer_question(question, chat_history)
    answer = response["answer"]
    logger.info(f"Generated answer: {answer}")
    
    source_documents = response.get("context", [])
    unique_sources = set()
    if source_documents:
        for doc in source_documents:
            if hasattr(doc, 'metadata') and 'source' in doc.metadata:
                source_path = doc.metadata['source']
                source_filename = os.path.basename(os.path.normpath(source_path))
                unique_sources.add(source_filename)
    
    logger.info(f"Retrieved sources: {unique_sources}")

    if unique_sources:
        sources_text = "\n\n---\n*å‚è€ƒæ¥æº:*\n" + "\n".join(f"- `{s}`" for s in sorted(list(unique_sources)))
        answer += sources_text
    
    return answer

def clear_chat():
    """Clears the chatbot and the message input box."""
    return [], ""

def upload_file(files):
    """Saves uploaded files to the docs directory."""
    if not files:
        return "æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ã€‚"

    for file in files:
        filename = os.path.basename(file.name)
        dest_path = os.path.join(DOCS_PATH, filename)
        
        # Read the content of the temporary file and write it to the destination
        with open(file.name, 'rb') as f_in:
            content = f_in.read()
        
        with open(dest_path, 'wb') as f_out:
            f_out.write(content)
            
        logger.info(f"Uploaded file '{filename}' to '{dest_path}'.")
        
    return f"æˆåŠŸä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶ã€‚å»ºè®®é‡å»ºçŸ¥è¯†åº“ã€‚"

# --- Custom CSS for visual optimization ---
custom_css = """
body {
    background-color: #f0f2f5;
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}
.gradio-container {
    border-radius: 15px !important;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
#rag-title {
    text-align: center;
    color: #2c3e50;
    font-size: 2.5em;
    padding: 20px 0;
}
"""

with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown("# åç”µé—®ç­”æœºå™¨äºº", elem_id="rag-title")
    
    with gr.Tab("æ™ºèƒ½é—®ç­”"):
        chatbot = gr.Chatbot(
            [],
            avatar_images=(None, "https://img.icons8.com/color/48/000000/robot-2.png"),
            elem_id="chatbot-main",
            label="èŠå¤©çª—å£"
        )
        
        with gr.Row():
            msg = gr.Textbox(
                label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                placeholder="åœ¨è¿™é‡Œè¾“å…¥é—®é¢˜ç„¶åæŒ‰ enter é”®",
                lines=1,
                show_label=False,
                scale=4
            )

        clear = gr.Button("ğŸ§¹ æ¸…é™¤å¯¹è¯")

        def respond(message, chat_history):
            bot_message = get_answer(message, chat_history)
            chat_history.append((message, bot_message))
            return "", chat_history

        msg.submit(respond, [msg, chatbot], [msg, chatbot], queue=True)
        clear.click(clear_chat, None, [chatbot, msg], queue=False)

    with gr.Tab("çŸ¥è¯†åº“æ–‡æ¡£"):
        file_status_msg = gr.Markdown("")
        
        with gr.Row():
            upload_button = gr.UploadButton("ğŸ“ ä¸Šä¼ æ–‡ä»¶", file_count="multiple")
            delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤æ‰€é€‰æ–‡ä»¶")
        
        doc_list = gr.CheckboxGroup(label="å¯ç”¨æ–‡æ¡£åˆ—è¡¨", value=lambda: list_docs(DOCS_PATH), interactive=True)
        
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ–‡æ¡£åˆ—è¡¨")

        # Actions
        upload_button.upload(
            upload_file,
            upload_button,
            [file_status_msg]
        ).then(
            lambda: gr.update(choices=list_docs(DOCS_PATH)),
            None,
            [doc_list]
        )

        delete_btn.click(
            delete_files,
            [doc_list],
            [file_status_msg]
        ).then(
            lambda: gr.update(choices=list_docs(DOCS_PATH), value=[]),
            None,
            [doc_list]
        )

        refresh_btn.click(lambda: gr.update(choices=list_docs(DOCS_PATH)), None, doc_list)

    with gr.Tab("ç®¡ç†é¢æ¿"):
        init_status = gr.Textbox(label="å¼•æ“çŠ¶æ€", interactive=False, value="æ­£åœ¨è‡ªåŠ¨åˆå§‹åŒ–...")
        rebuild_btn = gr.Button("ğŸ”„ å¼ºåˆ¶é‡å»ºçŸ¥è¯†åº“")
        
        def force_rebuild_rag():
            return init_rag(force_rebuild=True)
            
        rebuild_btn.click(force_rebuild_rag, None, init_status, queue=False)

    def initial_load():
        init_message = init_rag(force_rebuild=False)
        docs = list_docs(DOCS_PATH)
        return init_message, gr.update(choices=docs)

    demo.load(initial_load, None, [init_status, doc_list])

if __name__ == "__main__":
    demo.launch(server_name="127.0.0.1", share=True)